most organizations today depend on the use of data in two general ways standard business processes u
se data for executing transactions as well as supporting operational activities business analysts re
view data captured as a result of day to day operations through reports and analysis engines as a wa
ay of identifying new opportunities for efficiency or growth in other words data is used to both run
and improve the ways that organizations achieve their business objectives if that is true then there
must be processes in place to ensure that data is of sufficient quality to meet the business needs t
herefore it is of great value to any enterprise risk management program to incorporate a program tha
t includes processes for assessing measuring reporting reacting to and controlling the risks associa
ted with poor data quality flaws in any process are bound to introduce risks to successfully achieve
ng the objectives that drive your organizations daily activities if the flaws are introduced in a to
ypical manufacturing process that takes raw input and generates a single output the risks of signify
cant impact might be mitigated by closely controlling the quality of the process overseeing the acti
vities from end to end and making sure that any imperfections can be identified as early as possible
information is an asset that is generated through numerous processes with multiple feeds of raw data
that are combined processed and fed out to multiple customers both inside and outside your organizat
tion because data is of a much more dynamic nature created and used across the different operational
and analytical applications there are additional challenges in establishing ways to assess the risks
related to data failures as well as ways to monitor conformance to business user expectations this u
ncovers a deeper question to what extent does the introduction of flawed data impact the way that yo
ur organization does business while it is probably easy to point to specific examples of where unexp
ected data led to business problems there is bound to be real evidence of hard impacts that can be d
irectly associated with poor quality data anecdotes are strong motivators in that they raise awarene
ss of data quality as an issue but our intention is to develop a performance management framework th
at helps to identify isolate measure and improve the value of data within the environment the proble
is that the magnitude and challenge of correlating business impacts with data failures appears to be
too large to be able to manage  thus the reliance on anecdotes to justify an investment in good data
management practices but we can compare the job of characterizing the impacts of poor data quality t
eating an elephant it seems pretty big but if we can carve it down into small enough chunks it can b
done one bite at a time to be able to communicate the value of data quality improvement it is necess
ary to be able to characterize the loss of value that is attributable to poor data quality is inform
ation an organizational asset certainly if all a company does is accumulate store data there is some
cost associated with the ongoing management of that data the costs of storage maintenance office spa
support staff and so on and this could show up on the balance sheet as a liability though it is unli
kely that any corporation lists its data as a line item as either an asset or a liability on its bal
ance sheet there is no doubt that because of a significant dependence on data to both run and improv
the business senior managers at most organizations certainly rely on their data as much as any other
asset we can view data as an asset since data can be used to provide benefits to the company it is c
ontrolled by the organization it is the result of a sequence of transactions either as the result of
internal data creation internally or external data acquisition it incurs costs for acquisition and m
anagement and it is used to create value data is not treated as an asset though for example there is
no depreciation schedule for purchased data on the other hand the dependence of automated operationa
systems on data for processing clearly shows how data is used to create value transaction systems th
at manage the daily operations enable business as usual and when analytic systems are used for repor
ting performance management and discovery of new business opportunities the value of that informatio
shown yet again but it can be a challenge to assign a direct monetary value to any specific data val
for example while a computing system may expect to see a complete record to be processed a transacti
may still be complete even in the absence of some of the data elements does this imply that those da
elements have no value of course not otherwise there would not have been an expectation for those el
ements to be populated in the first place there are different ways of looking at information value t
simplest approaches consider the cost of acquisition ie the data is worth what we paid for it or its
market value ie what someone is willing to pay for it but in an environment where data is created st
ored processed exchanged shared aggregated and reused perhaps the best approach for understanding in
value is its utility the expected value to be derived from the information that value can grow as fu
nction of different aspects of the business ranging from strictly operational to strategic sales tra
are necessary to complete the sales process and therefore part of your sales revenues are related to
the data used to process the transaction daily performance reports are used to identify and eliminat
high cost low productivity activities and therefore the money saved is related to the data that comp
osed the report streamlined processing systems that expect high quality data can process many transa
ctions without human intervention and as the volume of processed transactions increases the cost per
transaction decreases which represents yet another utility value for dataall of these examples intro
an interesting point while it may be difficult in most instances to directly assign a monetary value
to a piece of data it is possible to explore how the utility value changes when the data does not me
business client expectations in other words it is possible to analyze how data is being used for ach
ieving business objectives and how the achievement of those goals is impeded when flawed data is int
roduced into the environment to do this we must consider the general approach to correlating busines
impacts to data quality issues is not new here are some interesting examples showing a variety of si
tuations in which data flaws contributed to serious risks and impacts managing credit risk is an imp
ortant task in any business particularly with respect to supplier management and spend analysis a su
rvey on credit risk data performed by pricewaterhousecoopers suggested that a significant percentage
the top banks were deficient in credit risk data management areas of particular concern included cou
nterparty data repositories counterparty hierarchy data common counterparty identifiers and consiste
nt data standards in an example in which data is deliberately introduced or modified the association
of certified fraud examiners noted in their  report to the nation a number of different methods that
employees use to generate fraudulent payments as a byproduct of employees introducing incorrect or i
nvalid data there is an increase in improper disbursements and the report provides details about the
costs associated with these fraud payments attempting to link business impacts to data quality issue
is not a new idea as can be seen by the way the us department of defense dod categorized business im
pacts in their guidelines on data quality in  the dod looked at four specific areas prevention appra
isal internal failure and external failure and then sought to correlate impacts and their relative c
osts in relation to the types of data errors that occurred by looking at the types of data errors it
was suggested that it would be reasonable to assess the value improvement that could be gained by co
rrecting problems as opposed to costs incurred by ignoring them and then determine the next steps by
refining the types of costs eg direct versus indirect costs analysts could get a better idea about p
rioritizing remediation tasks for example the report documents how poor data quality impacts specifi
business processes the inability to match payroll records to the official employment record can cost
millions in payroll overpayments to deserters prisoners and ghost soldiers in addition the inability
to correlate purchase orders to invoices is a major problem in unmatched disbursements ntl a cable o
perator in the united kingdom sought to apply data quality techniques in order to improve efficiency
of an operators network and found that invalid data was responsible for discrepancies between servic
provided and services invoiced the result was an exposure of wasted unknown capacity as well as unde
rbilling in turn they were able to achieve a return on investment the data quality improvement progr
am was essentially selffunded by analyzing revenue assurance to detect underbilling for example resu
indicated leakage of just over  percent of total revenue a  survey prepared by consulting company er
nst young attempted to bring to light the importance of data quality specifically within the insuran
industry the report noted that shortcomings in exposure data quality are common and that not many in
surers are doing enough to correct these shortcomings the report called out some specific types of d
ata flaws including missing or inaccurate values associated with insured values locations building c
lass and occupancy class as well as additional characteristics often business applications that do n
ot meet expectations are scheduled for renovation or replacement however if the root cause of the ap
plication failure is due to inherent data issues leading to organizational mistrust updating the app
lication will not eliminate the source of missed expectations we have seen a common pattern in which
financial investment in hardware software and resources for software development has been made to re
novate business application systems yet the deployment of those systems is delayed or perhaps even c
anceled because of organizational mistrust of the underlying data we call this a development risk si
nce the cost and the potential value of the new application cannot be actualized until the data issu
have been resolved when attempting to assemble a comprehensive system of record or a master data man
agement program it is important to be able to integrate data from across many different systems erro
rs and flaws in the data impact the consolidation process when they are left unaddressed and will re
quire additional and unusually unexpected effort for remediation before integration in the health ca
there can be serious health risks associated with incorrect data an obvious severe example is the ca
of heart transplant patient jesica santillan where inaccurate information regarding blood typing res
ulted in a botched heart lung transplant which not only led to the girls death but also prevented ot
her critically ill patients from receiving needed donated organs although there may be disagreements
about the number of critical events that are attributable to medical errors discrepancies related to
incorrect or invalid information are often identifiable as the root cause more often information pol
icies expressed through external channels introduce constraints for example privacy security and lim
itation of use are introduced within governmental dictates at the national state or provincial and c
ounty municipal or jurisdictional eg courts levels as an example of privacy risk in the health insur
portability and accountability act of  hipaa the regulatory aspect underscores health insurers ethic
responsibility to ensure patient privacy properly capturing and managing data related to with whom a
individuals health information may be shared impact many aspects of that persons life ranging from p
rotection against physical abuse to employment discrimination among others exposure to operational f
raud may be masqueraded throughout your applications when fraudulent behavior is performed to exploi
information failures within the system the lack of quality of ensuring unique identification of indi
viduals orders and so on enables unscrupulous characters to run roughshod over your business the cha
llenge many institutions are facing can be illustrated by a simple example a few years ago a man was
able to fool the computer fraud programs at two musicbymail clubs by using  aliases he repeatedly ex
ploited the clubs introductory offers that typically provided a large number of free cds with the pu
of one cd at the regular price then resold the discs at a profit although this book presents four hi
ghlevel impact classifications these are not necessarily inclusive if within your organization there
are additional highlevel classes with their own impact categories it is desirable to document the ne
class and the categories that belong to that class alternatively the categories provided in this cha
may still be at too gross a level requiring further segmentation take an iterative approach use this
chapters impact categorization scheme as a model that can be tweaked and modified classify the impac
ts into a taxonomic hierarchy that shows how small impacts will roll up at different levels and ulti
mately feed into a data quality scorecard the objectives of designing an impact hierarchy are twofol
our original intention of determining how poor data quality impacts our business processes is a much
manageable task when it can be broken up into small analytic pieces but more interestingly the categ
orical hierarchy of impact areas will naturally map to our future performance reporting structure fo
gauging improvement as we identify where poor data quality impacts the business we will also be iden
tifying where data quality improvement will enhance the business this provides a solid framework for
quantifying measurable performance metrics that will eventually be used to craft key data quality pe
indicators and we will continue to explore the manifestation of these ideas in as opposed to the tas
in a vicious cycle when executing the tasks in a virtuous cycle the data quality practitioner provid
positive feedback that leads to overall improvement in the quality of organizational information acr
oss the board each time we cycle through our virtuous cycle the effects are to increase the value of
ways that an organizations information asset supports the achievement of business objectives as show
in figure the virtuous cycle consists of five stages during the first stage the practitioner seeks t
understand the scope of how poor data quality affects the ways that the business processes are inten
ded to run this is a combination of topdown and a bottomup approaches the topdown activity surveys t
business users of the data to document what they do how they use information and what their most sig
nificant sources of pain are with respect to data the bottomup component employs statistical and dat
analysis tools and techniques such as data profiling to identify potential data anomalies that can b
reviewed with subject matter experts during the second stage the data quality analysts synthesize th
results of both the topdown and bottomup activities and concentrate on the data elements that are de
emed critical based on the selected business users needs in turn the results of the empirical analys
is will provide some types of measures that can be employed to assess the levels of data quality wit
hin a particular business context any areas of interest in which the data does not meet the acceptab
ility thresholds are candidates for review which leads to stage three during this stage the data qua
lity issues are prioritized based on their severity as well as the feasibility for remediation a pla
developed and selected solutions are designed once those solutions have been designed the fourth sta
is to actually implement them the remediation may consist of corrections inspections and notificatio
and may not be limited to installing tools but may involve training staff members on operational pro
cess improvements having identified data quality rules and acceptability thresholds in stage two and
having developed methods for measuring the data against those rules stage five allows the data quail
ty analysts to review the degree to which the data does or does not meet the levels of acceptability
if there are issues to be researched the data stewards are notified and a separate resolution proces
is kicked off meanwhile this brings us to the beginning again in which a different data set or a dif
ferent business process is selected there is an apparent duality in the phasing of these tasks the f
irst two tasks are analysis tasks used to assess a target data set and figure out if there are any e
gregious errors that are impacting the business the third fourth and fifth tasks are the action task
intended to put together a plan of attack and execute against that plan together these two phases pr
ovide a repeatable process for incrementally accumulating metrics for data quality that will contrib
ute to populating a data quality scorecard and a data quality dashboard as well as driving proactive
data quality management this chapter will provide a survey of the processes that contribute to the e
xecution of the virtuous cycle consider the roles of the associated stakeholders and participants an
how responsibilities and accountabilities are allocated across that landscape to implement the phase
of the virtuous cycle the data quality practitioners must institute a number of processes as shown i
the brief description of these processes provided here collectively establishes the context for subs
equent sections of the book during this process the data quality analyst will note any potential dat
arelated issues that increase costs reduce revenues impact margins or introduce inefficiencies or de
lays in business activities any other negative business impacts that are attributable to data that d
meet a specific level of acceptability are also noted this qualitative review is the first step in u
nderstanding whether there are critical pain points and in which parts of the business process these
points of pain have greatest impact as a result the analyst will scope the business requirements for
information for the assessment narrow the list of data sets that will be examined and guide the iden
tification of data quality requirements this process is a topdown identification of data quality exp
ectations at this point the analysts will synthesize data quality expectations for consumed data set
based on the business impact analysis data sets will be identified and targeted for assessment and s
dimensions of data quality will be isolated the selected dimensions will be used to list specific me
asures that will be evaluated in relation to the business impacts this process performs a bottomup e
mpirical approach to identifying potential data issues using data profiling and other statistical an
analysis techniques the analysts can identify potential data anomalies which are noted in preparatio
business review this process is to review discovered anomalies with business clients within the cont
ext of the documented business impacts during this process the analysts work with the business subje
matter experts to differentiate between relevant and irrelevant issues prioritize issues based on bu
siness impact and explore different strategies for remediation in addition at this point the busines
users can be solicited to define their data requirements correlating business impacts to data issues
defined business rules allows one to represent different measurable aspects of data quality these me
asures can be used in characterizing relevance across a set of application domains to support data q
saintliness wearyingly shampoo headstone syrian elapse between eigenstate suspends deferentially amu